# LLM Attention Dynamics

A tool for visualizing and comparing how different Language Models allocate attention to a prompt during text generation. The interface has a step-by-step slider that you can use to see how each model's attention patterns change during generation, showing which parts of your prompt receive more attention at each step of the response. The visualization represents attention scores averaged across attention heads & transformer layers through color intensity.

https://github.com/user-attachments/assets/c51bffd1-c68e-43ff-8896-456194918efd

